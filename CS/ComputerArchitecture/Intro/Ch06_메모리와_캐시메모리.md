# RAM의 특징과 종류

## RAM의 특징

- `휘발성 저장 장치(volatile memory)` : 전원을 끄면 저장된 내용이 사라지는 저장 장치
- `비휘발성 저장 장치(non-volatile memory)` : 전원이 꺼져도 저장된 내용이 유지되는 저장 장치

일반적으로 보조기억장치인 비휘발성 저장 장치에는 ‘보관할 대상’을 저장하고, 휘발성 저장장치인 RAM에는 ‘실행할 대상’을 저장한다.

## RAM의 용량과 성능

RAM 용량이 적다면 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어진다. 

RAM 용량이 충분히 크다면 보조기억장치에서 많은 데이터를 가져와 미리 RAM에 저장할 수 있다. 즉, _RAM 용량이 크면 많은 프로그램들을 동시에 빠르게 실행하는 데 유리하다._

그렇다고 용량이 필요 이상으로 커졌을 때 속도가 그에 비례하여 증가하지는 않는다.

## RAM의 종류

### DRAM

- `DRAM(Dynamic RAM)`
- 저장된 데이터가 동적으로 변하는(사라지는) RAM을 의미
- 시간이 지나면 저장된 데이터가 점차 사라진다.
- _데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)해야 한다._
- 소비 전력이 비교적 낮고, 저렴하고, 집적도가 높기 때문에 대용량으로 설계하기가 용이하다.
    </br>→ 일반적으로 메모리로써 사용됨
    

### SRAM

- `SRAM(Static RAM)`
- 저장된 데이터가 변하지 않는 RAM
- 주기적인 데이터 재활성화가 필요없기 때문에 _일반적으로  DRAM보다 속도가 더 빠르다._
- 집적도가 낮고, 소비 전력도 크며, 가격도 더 비싸다.
    
    → 메모리가 아닌 ‘대용량으로 만들어질 필요는 없지만 속도가 빨라야 하는 저장 장치’, 가령 _캐시 메모리에서 사용된다._
    

### SDRAM

- SDRAM(Synchronous Dynamic RAM)
- 클럭 신호와 동기화된, 발전된 형태의 DRAM
- _클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있다._

### DDR SDRAM

- DDR SDRAM(Double Data Rate SDRAM)
- 최근 가장 흔히 사용되는 RAM
- 대역폭을 넓혀 속도를 빠르게 만든 SDRAM
    - `대역폭(data rate)` : 데이터를 주고받는 길의 너비
- 한 클럭에 한 번씩 CPU와 데이터를 주고받을 수 있는 _SDRAM에 비해 DDR SDRAM은 두 배의 대역폭으로 한 클럭 당 두 번씩 CPU와 데이터를 주고받을 수 있다._
    
    → 전송 속도가 두 배가량 빠르다.
    
    - 한 클럭당 하나씩 데이터를 주고받을 수 있는 SDRAM을 SDR SDRAM(Single Data Rate SDRAM)이라 부르기도 한다.
    - 최근에 흔히 사용되는 메모리는 DDR4 SDRAM으로, SDR SDRAM보다 16배 넓은 대역폭을 가진다.
    

# 메모리의 주소 공간

## 물리 주소와 논리 주소

- `물리 주소(physical address)`
    - **메모리**가 사용
    - 정보가 실제로 저장된 하드웨어상의 주소
- `논리 주소(logical address)`
    - **CPU와 실행 중인 프로그램**이 사용
    - 실행 중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소

메모리가 사용하는 주소는 하드웨어상의 실제 주소인 물리 주소이고, CPU와 실행 중인 프로그램이 사용하는 주소는 각각의 프로그램에 부여된 논리 주소이다.

CPU가 메모리와 상호작용하려면 논리 주소와 물리 주소 간의 변환이 이루어져야 한다. 논리 주소와 물리 주소 간의 변환은 CPU와 주소 버스 사이에 위치한 `메모리 관리 장치(MMU; Memory Management Unit)`라는 하드웨어에 의해 수행된다. MMU는 _CPU가 발생시킨 논리 주소에 베이스 레지스터 값을 더하여 논리 주소를 물리 주소로 변환한다._

`베이스 레지스터`는 프로그램의 가장 작은 물리 주소, 즉 프로그램의 첫 물리 주소를 저장하는 셈이고, `논리 주소`는 프로그램의 시작점으로부터 떨어진 거리인 셈이다.

![](https://velog.velcdn.com/images/ncookie/post/9e8daa18-c9f8-4cd4-a1b0-e4f50c47c133/image.png)

## 메모리 보호 기법

_다른 프로그램의 영역을 침범할 수 있는 명령어는 위험하기 때문에 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요하다._ 이는 `한계 레지스터(limit register)`라는 레지스터가 담당한다.

한계 레지스터는 _논리 주소의 최대 크기를 저장한다._ 즉, 프로그램의 물리 주소 범위는 베이스 레지스터 값 이상, 베이스 레지스터 + 한계 레지스터 값 미만이 된다.

![](https://velog.velcdn.com/images/ncookie/post/efe37d3f-8ac6-4777-9a75-a8ee7cf47ad4/image.png)

_CPU가 접근하려는 논리 주소는 한계 레지스터가 저장한 값보다 커서는 안된다._ CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사한다. 만약 _CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트(트랩)를 발생시켜 실행을 중단한다._

이러한 방식으로 실행 중인 프로그램의 독립적인 실행 공간을 확보하고 하나의 프로그램이 다른 프로그램을 침범하지 못하게 보호할 수 있다.

# 캐시 메모리

## 저장 장치 계층 구조

저장 장치는 일반적으로 아래와 같은 명제를 따른다.

1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

컴퓨터가 사용하는 저장 장치들은 _‘CPU에 얼마나 가까운가’_ 를 기준으로 계층적으로 나타낼 수 있다. 이를 `저장 장치 계층 구조(memory hierarchy)`라고 한다.

> 저장 장치 계층 구조를 영문으로 나타내면 memory hierarchy, 메모리 계층 구조를 의미한다. 여기서 ‘메모리’라는 용어는 RAM이 아닌 일반적인 저장 장치를 의미한다. 때문에 여기서는 용어의 혼동을 방지하기 위해 ‘저장 장치 계층 구조’라는 표현을 사용한다.
> 

![](https://velog.velcdn.com/images/ncookie/post/9eddf8fe-d645-406a-8590-e3ba522224a6/image.png)

## 캐시 메모리

`캐시 메모리(cache memory)`는 CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치이다. 

캐시 메모리는 _CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생했다._ 이를 위해 _메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용한다._

컴퓨터 내부에는 여러 개의 캐시 메모리가 있는데, 이들은 CPU(코어)와 가까운 순서대로 계층을 구성한다. 코어와 가장 가까운 캐시 메모리를 L1(level 1) 캐시, 그 다음 가까운 캐시 메모리를 L2(level 2) 캐시, 그 다음 가까운 캐시 메모리를 L3(level 3) 캐시라고 부른다. 

CPU가 메모리 내에 데이터가 필요하다고 판단하면 우선 L1 캐시에 해당 데이터가 있는지를 알아보고, 없다면 L2, L3 캐시 순으로 데이터를 검색한다. L1 캐시와 L2 캐시는 코어마다 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 사용된다.

> 코어와 가장 가까운 L1 캐시는 조금이라도 접근 속도를 빠르게 만들기 위해 명령어만을 저장하는 L1 캐시인 L1I 캐시와 데이터만을 저장하는 L1 캐시인 L1D 캐시로 분리하는 경우도 있다.  이를 `분리형 캐시(split cache)`라고 한다.

## 참조 지역성 원리

캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장한다. 이 때 _자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에 활용될 경우를_ `캐시 히트(cache hit)`라고 한다.

반대로 자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, _예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를_ `캐시 미스(cache miss)`라고 한다. 캐시 미스가 발생하면 CPU가 필요한 데이터를 메모리에서 직접 가져와야 하기 때문에 캐시 메모리의 이점을 활용할 수 없다. 당연히 _캐시 미스가 자주 발생하면 성능이 떨어지게 된다._

캐시가 히트되는 비율을 `캐시 적중률(cache hit ratio)`이라 하고 다음과 같이 계산한다.

**캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)**

캐시 메모리는 `참조 지역성의 원리(locality of reference, principle of locality)`라는 원칙에 따라 메모리로부터 가져올 데이터를 결정한다. 참조 지역성의 원리란 _CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리이다._

1. **최근에 접근했던 메모리 공간에 다시 접근하려는 경향**

변수에 값을 저장하고 나면 언제든 변수에 다시 접근하여 변수에 저장된 값을 사용할 수 있다. 이는 _‘CPU는 변수가 저장된 메모리 공간을 언제든 다시 참조할 수 있다’_ 는 것을 의미한다. 이러한 경향을 `시간 지역성(temporal locality)`라고 한다.

2. **접근한 메모리 공간 근처를 접근하려는 경향**

CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여 있다. 하나의 프로그램 내에서도 관련 있는 데이터들은 모여서 저장된다. CPU는 프로그램을 실행할 때 그 프로그램이 모여 있는 공간 근처와 사용하는 기능들이 모여 있는 공간 근처를 집중적으로 접근할 것이다. 이러한 경향을 `공간 지역성(spatial locality)`라고 한다.
